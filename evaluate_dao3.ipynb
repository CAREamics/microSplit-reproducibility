{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from typing import Literal, Optional, Union\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import ml_collections\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from careamics.config.likelihood_model import NMLikelihoodConfig\n",
    "from careamics.config.nm_model import MultiChannelNMConfig\n",
    "from careamics.config import VAEAlgorithmConfig\n",
    "from careamics.lightning import VAEModule\n",
    "from careamics.lvae_training.eval_utils import (\n",
    "    Calibration,\n",
    "    get_calibrated_factor_for_stdev,\n",
    "    get_dset_predictions,\n",
    "    get_eval_output_dir,\n",
    "    plot_calibration,\n",
    "    plot_error,\n",
    "    show_for_one,\n",
    "    stitch_predictions,\n",
    ")\n",
    "from careamics.config.architectures import LVAEModel\n",
    "from careamics.config.nm_model import GaussianMixtureNMConfig, MultiChannelNMConfig\n",
    "from careamics.config.likelihood_model import (\n",
    "    GaussianLikelihoodConfig,\n",
    "    NMLikelihoodConfig,\n",
    ")\n",
    "from careamics.config.loss_model import LVAELossConfig, KLLossConfig\n",
    "\n",
    "from careamics.lvae_training.eval_utils import stitch_predictions_new\n",
    "from careamics.config.optimizer_models import LrSchedulerModel, OptimizerModel\n",
    "from careamics.models.lvae.noise_models import noise_model_factory\n",
    "from careamics.utils.metrics import (\n",
    "    # avg_psnr,\n",
    "    # avg_range_inv_psnr,\n",
    "    # avg_ssim,\n",
    "    scale_invariant_psnr,\n",
    "    # multiscale_ssim\n",
    ")\n",
    "# TODO: sorry for this :(\n",
    "sys.path.insert(0, \"/home/federico.carrara/Documents/projects/microSplit-reproducibility/\")\n",
    "sys.path.insert(0, \"/home/igor.zubarev/projects/microSplit-reproducibility/\")\n",
    "\n",
    "from data import (\n",
    "    LCMultiChDloader, MultiChDloader, DataSplitType, DataType\n",
    ")\n",
    "from data.data_utils import GridAlignement, load_tiff\n",
    "\n",
    "from datasets import load_train_val_sox2golgi_v2, create_train_val_datasets\n",
    "from configs.sox2golgi_v2 import get_data_configs\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seeds():\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "fix_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/localscratch/data/taverna/TavernaSox2Golgi/acquisition2/'\n",
    "OUT_ROOT = '/home/igor.zubarev/data/splits/'\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = os.path.join(OUT_ROOT, '2410/denoisplit_with_LC/12')\n",
    "assert os.path.exists(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Set Evaluation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbdfebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom parameters # TODO move to a separate file\n",
    "img_size: int = [64, 64]\n",
    "\"\"\"Spatial size of the input image.\"\"\"\n",
    "target_channels: int = 2\n",
    "\"\"\"Number of channels in the target image.\"\"\"\n",
    "multiscale_count: int = 3\n",
    "\"\"\"The number of LC inputs plus one (the actual input).\"\"\"\n",
    "predict_logvar: Optional[Literal[\"pixelwise\"]] = \"pixelwise\"\n",
    "\"\"\"Whether to compute also the log-variance as LVAE output.\"\"\"\n",
    "loss_type: Optional[Literal[\"musplit\", \"denoisplit\", \"denoisplit_musplit\"]] = \"denoisplit_musplit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set eval parameters\n",
    "mmse_count: int = 10\n",
    "\"\"\"The number of predictions to average for MMSE evaluation.\"\"\"\n",
    "image_size_for_grid_centers: int = 32\n",
    "\"\"\"The size of the portion of image we retain from inner padding/tiling.\"\"\"\n",
    "eval_patch_size: Optional[int] = 64\n",
    "\"\"\"The actual patch size. If not specified data.image_size.\"\"\"\n",
    "psnr_type: Literal['simple', 'range_invariant'] = 'range_invariant'\n",
    "\"\"\"The type of PSNR to compute.\"\"\"\n",
    "which_ckpt: Literal['best', 'last'] = 'last'\n",
    "\"\"\"Which checkpoint to use for evaluation.\"\"\"\n",
    "enable_calibration: bool = False\n",
    "\"\"\"Whether to enable calibration.\"\"\"\n",
    "eval_datasplit_type = DataSplitType.Test\n",
    "\"\"\"The data split used for evaluation.\"\"\"\n",
    "batch_size: int = 32\n",
    "\"\"\"Batch size for data loader.\"\"\"\n",
    "num_workers = 4\n",
    "\"\"\"Number of workers for data loader.\"\"\"\n",
    "use_deterministic_grid = None\n",
    "\"\"\"Whether to use a deterministic grid for evaluation (i.e., get a random patch).\"\"\"\n",
    "data_t_list = None\n",
    "\"\"\"List of indexes of the data to be used (e.g., for debugging or picking a particular image).\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Load config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to a separate file\n",
    "def get_model_checkpoint(\n",
    "    ckpt_dir: str, mode: Literal['best', 'last'] = 'best'\n",
    ") -> str:\n",
    "    output = []\n",
    "    for fpath in glob.glob(ckpt_dir + \"/*.ckpt\"):\n",
    "        fname = os.path.basename(fpath)\n",
    "        if mode == 'best':\n",
    "            if fname.startswith('best'):\n",
    "                output.append(fpath)\n",
    "        elif mode == 'last':\n",
    "            if fname.startswith('last'):\n",
    "                output.append(fpath)\n",
    "    assert len(output) == 1, '\\n'.join(output)\n",
    "    return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to a separate file\n",
    "\n",
    "def load_file(file_path: str):\n",
    "    # Get the file extension\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "\n",
    "    # Check the extension and load the file accordingly\n",
    "    if ext == '.pkl':\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    elif ext == '.json':\n",
    "        with open(file_path) as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file extension: {ext}. Only .pkl and .json are supported.\")\n",
    "\n",
    "def load_config(config_fpath: str, config_type: Literal['algorithm', 'training', 'data']) -> dict:\n",
    "    for fname in glob.glob(os.path.join(config_fpath, '*config.*')):\n",
    "        fname = os.path.basename(fname)\n",
    "        if fname.startswith(config_type):\n",
    "            return load_file(os.path.join(config_fpath, fname))\n",
    "    raise ValueError(f\"Config file not found in {config_fpath}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(ckpt_dir):\n",
    "    algo_config = load_config(ckpt_dir, \"algorithm\")\n",
    "    training_config = load_config(ckpt_dir, \"training\")\n",
    "    data_config = load_config(ckpt_dir, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_config, val_data_config, test_data_config = get_data_configs()\n",
    "# training_config = TrainingConfig()\n",
    "train_dset, val_dset, test_dset, data_stats = create_train_val_datasets(\n",
    "    datapath=DATA_DIR,\n",
    "    train_config=train_data_config,\n",
    "    val_config=val_data_config,\n",
    "    test_config=test_data_config,\n",
    "    load_data_func=load_train_val_sox2golgi_v2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Actual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some params\n",
    "# TODO: check if this is right\n",
    "if eval_patch_size is not None:\n",
    "    training_image_size = data_config[\"image_size\"]\n",
    "    data_config[\"image_size\"] = eval_patch_size\n",
    "\n",
    "if image_size_for_grid_centers is not None:\n",
    "    training_grid_size = data_config.get(\"grid_size\", \"grid_size not present\")\n",
    "    data_config[\"grid_size\"] = image_size_for_grid_centers\n",
    "\n",
    "padding_kwargs = {\"mode\": \"reflect\"}\n",
    "dset_kwargs = {\n",
    "    \"overlapping_padding_kwargs\": padding_kwargs,\n",
    "    \"grid_alignment\": GridAlignement.Center\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b774076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Noise-free dataset (High-SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9748c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d36d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_data_config:\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Note: noise model and the associated likelihood are not saved in the config, hence we need to reinitialize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nm_paths: Optional[tuple[str]] = [\n",
    "    \"/group/jug/ashesh/training/noise_model/2405/4/GMMNoiseModel_Dao3Channel-SIM1__6_4_Clip0.0-1.0_Sig0.125_UpNone_Norm0_bootstrap.npz\",\n",
    "    \"/group/jug/ashesh/training/noise_model/2405/5/GMMNoiseModel_Dao3Channel-SIM1__6_4_Clip0.0-1.0_Sig0.125_UpNone_Norm0_bootstrap.npz\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split_lightning_model(\n",
    "    algorithm: str,\n",
    "    loss: str,\n",
    "    model_parameters: dict,\n",
    "    data_config: dict,\n",
    "    training_config = None,\n",
    ") -> VAEModule:\n",
    "    \"\"\"Instantiate the muSplit lightining model.\"\"\"\n",
    "    lvae_config = LVAEModel(\n",
    "        architecture=\"LVAE\",\n",
    "        input_shape=model_parameters[\"img_size\"],\n",
    "        multiscale_count=model_parameters[\"multiscale_count\"],\n",
    "        z_dims=[128, 128, 128, 128],\n",
    "        output_channels=model_parameters[\"target_ch\"],\n",
    "        predict_logvar=model_parameters[\"predict_logvar\"],\n",
    "        analytical_kl=False,\n",
    "    )\n",
    "\n",
    "    # gaussian likelihood\n",
    "    if loss in [\"musplit\", \"denoisplit_musplit\"]:\n",
    "        gaussian_lik_config = GaussianLikelihoodConfig(\n",
    "            predict_logvar=model_parameters[\"predict_logvar\"],\n",
    "            logvar_lowerbound=-5.0,  # TODO: find a better way to fix this\n",
    "        )\n",
    "    else:\n",
    "        gaussian_lik_config = None\n",
    "    # noise model likelihood\n",
    "    if loss in [\"denoisplit\", \"denoisplit_musplit\"]:\n",
    "        gmm_list = []\n",
    "        for NM_path in model_parameters[\"nm_paths\"]:\n",
    "            gmm_list.append(\n",
    "                GaussianMixtureNMConfig(\n",
    "                    model_type=\"GaussianMixtureNoiseModel\",\n",
    "                    path=NM_path,\n",
    "                )\n",
    "            )\n",
    "        noise_model_config = MultiChannelNMConfig(noise_models=gmm_list)\n",
    "        nm_lik_config = NMLikelihoodConfig(\n",
    "            data_mean=data_config[\"data_stats\"][0],\n",
    "            data_std=data_config[\"data_stats\"][1],\n",
    "        )\n",
    "    else:\n",
    "        noise_model_config = None\n",
    "        nm_lik_config = None\n",
    "\n",
    "    loss_config = LVAELossConfig(\n",
    "        loss_type=loss,\n",
    "        kl_params=KLLossConfig()\n",
    "    )\n",
    "\n",
    "    opt_config = OptimizerModel(\n",
    "        name=\"Adamax\",\n",
    "        parameters={\n",
    "            \"lr\": training_config[\"lr\"],\n",
    "            \"weight_decay\": 0,\n",
    "        },\n",
    "    )\n",
    "    lr_scheduler_config = LrSchedulerModel(\n",
    "        name=\"ReduceLROnPlateau\",\n",
    "        parameters={\n",
    "            \"mode\": \"min\",\n",
    "            \"factor\": 0.5,\n",
    "            \"patience\": training_config[\"lr_scheduler_patience\"],\n",
    "            \"verbose\": True,\n",
    "            \"min_lr\": 1e-12,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    vae_config = VAEAlgorithmConfig(\n",
    "        algorithm_type=\"vae\",\n",
    "        algorithm=algorithm,\n",
    "        loss=loss_config,\n",
    "        model=lvae_config,\n",
    "        gaussian_likelihood=gaussian_lik_config,\n",
    "        noise_model=noise_model_config,\n",
    "        noise_model_likelihood=nm_lik_config,\n",
    "        optimizer=opt_config,\n",
    "        lr_scheduler=lr_scheduler_config,\n",
    "    )\n",
    "\n",
    "    return VAEModule(algorithm_config=vae_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97434476",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = create_split_lightning_model(\n",
    "        algorithm=\"denoisplit\",\n",
    "        loss=\"denoisplit_musplit\",\n",
    "        model_parameters={\"img_size\": img_size,\n",
    "        \"multiscale_count\": multiscale_count,\n",
    "        \"predict_logvar\": predict_logvar,\n",
    "        \"target_ch\": target_channels,\n",
    "        \"nm_paths\": nm_paths},\n",
    "        data_config={\"data_stats\": data_stats},\n",
    "        training_config=training_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(ckpt_dir):\n",
    "    ckpt_fpath = get_model_checkpoint(ckpt_dir, mode=which_ckpt)\n",
    "else:\n",
    "    assert os.path.isfile(ckpt_dir)\n",
    "    ckpt_fpath = ckpt_dir\n",
    "\n",
    "print(f\"Loading checkpoint from: '{ckpt_fpath}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(ckpt_fpath)\n",
    "\n",
    "lightning_model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "lightning_model.eval()\n",
    "lightning_model.cuda()\n",
    "\n",
    "print('Loading weights from epoch', checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### From here on we perform evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Visualize Data: noisy & ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "#### Compute predictions and related metrics (PSNR) for the entire validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee338c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset.dsets = test_dset.dsets[:1] # otherwise it's too long and crashes cuz of memory leak! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: here, patch-wise PSNR is used, hence results are not trustworthy\n",
    "pred_tiled = get_dset_predictions(\n",
    "  model=lightning_model,\n",
    "  dset=test_dset,\n",
    "  batch_size=batch_size,\n",
    "  num_workers=num_workers,\n",
    "  mmse_count=mmse_count,\n",
    "  loss_type=algo_config[\"loss\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9774661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = np.round([x.item() for x in patch_psnr_tuple], 2)\n",
    "# print(f\"Patch wise PSNR, as computed during training {tmp}, avg: {np.mean(tmp)}\")\n",
    "print(f'Number of predicted tiles: {pred_tiled.shape[0]}, channels: {pred_tiled.shape[1]}, shape: {pred_tiled.shape[2:]}')\n",
    "# print(f'Reconstruction loss distrib: {np.quantile(rec_loss, [0,0.01,0.5, 0.9,0.99,0.999,1]).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Get full image predictions by stitching the predicted tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Stitch predicted tiled logvar\n",
    "# if len(np.unique(logvar_tiled)) == 1:\n",
    "#     logvar = None\n",
    "# else:\n",
    "#     logvar = stitch_predictions(logvar_tiled, val_dset, smoothening_pixelcount=0) # TODO: there's a bug here\n",
    "\n",
    "# Stitch the std of the predictions (i.e., std computed on the mmse_count predictions)\n",
    "if pred_tiled.shape[-1] != test_dset.get_img_sz():\n",
    "    pad = (val_dset.get_img_sz() - pred_tiled.shape[-1] )//2\n",
    "    pred_tiled = np.pad(pred_tiled, ((0,0),(0,0),(pad,pad),(pad,pad)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stitch tiled predictions\n",
    "pred = stitch_predictions_new(\n",
    "    pred_tiled,\n",
    "    test_dset.dsets[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Ignore (and remove) the pixels which are present in the last few rows and columns (since not multiples of patch_size)\n",
    "1. They don't come in the batches. So, in prediction, they are simply zeros. So they are being are ignored right now. \n",
    "2. For the border pixels which are on the top and the left, overlapping yields worse performance. This is becuase, there is nothing to overlap on one side. So, they are essentially zero padded. This makes the performance worse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ignored_pixels():\n",
    "    \"\"\"Get the number of ignored pixels in the predictions.\n",
    "    \n",
    "    Given the current predictions `pred`, analyze the first image std\n",
    "    to find the number of pixels that are ignored in prediction.\n",
    "    \"\"\"\n",
    "    ignored_pixels = 1\n",
    "    while(pred[0, -ignored_pixels:, -ignored_pixels:,].std() == 0):\n",
    "        ignored_pixels+=1\n",
    "    ignored_pixels-=1\n",
    "    print(f'In {pred.shape}, last {ignored_pixels} many rows and columns are all zero.')\n",
    "    return ignored_pixels\n",
    "\n",
    "actual_ignored_pixels = get_ignored_pixels()\n",
    "print(f'Actual ignored pixels: {actual_ignored_pixels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_config[\"data_type\"] in [\n",
    "    DataType.OptiMEM100_014,\n",
    "    DataType.SemiSupBloodVesselsEMBL,\n",
    "    DataType.Pavia2VanillaSplitting,\n",
    "    DataType.ExpansionMicroscopyMitoTub,\n",
    "    DataType.ShroffMitoEr,\n",
    "    DataType.HTIba1Ki67\n",
    "]:\n",
    "    ignored_last_pixels = 32\n",
    "elif data_config[\"data_type\"] == DataType.BioSR_MRC:\n",
    "    ignored_last_pixels = 44\n",
    "elif data_config[\"data_type\"] == DataType.NicolaData:\n",
    "    ignored_last_pixels = 8\n",
    "else:\n",
    "    ignored_last_pixels = 0\n",
    "\n",
    "ignore_first_pixels = 0\n",
    "# assert actual_ignored_pixels <= ignored_last_pixels, f'Set ignored_last_pixels={actual_ignored_pixels}' # TODO: check this once stitching is fixed\n",
    "print(ignored_last_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = test_dset.dsets[0]._data\n",
    "\"\"\"Data used to do evaluation againts. Shape is (N, H, W, C).\n",
    "\n",
    "NOTE: this is the original data (`dset._data`), hence not normalized!\n",
    "\"\"\"\n",
    "\n",
    "if DEBUG:\n",
    "    if 'target_idx_list' in data_config and data_config.target_idx_list is not None:\n",
    "        tar = tar[..., data_config.target_idx_list]\n",
    "\n",
    "def ignore_pixels(\n",
    "    arr: Union[np.ndarray, torch.Tensor],\n",
    "    patch_size: int\n",
    ") -> Union[np.ndarray, torch.Tensor]:\n",
    "    \"\"\"Remove pixels that are ignored in the predictions.\"\"\"\n",
    "    if arr.shape[2] % patch_size:\n",
    "        if ignore_first_pixels:\n",
    "            arr = arr[:,ignore_first_pixels:,ignore_first_pixels:]\n",
    "        if ignored_last_pixels:\n",
    "            arr = arr[:,:-ignored_last_pixels,:-ignored_last_pixels]\n",
    "    return arr\n",
    "\n",
    "pred = ignore_pixels(pred, val_dset.get_img_sz())\n",
    "tar = ignore_pixels(tar, val_dset.get_img_sz())\n",
    "# if pred_std is not None:\n",
    "#     pred_std = ignore_pixels(pred_std, val_dset.get_img_sz())\n",
    "\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "#### Perform Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570323b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move calibration to a separate file !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Plot RMV vs. RMSE without Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "Observe that the plot is far from resembling y = x!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "#### Visually compare Targets and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c05d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = data_stats[0]\n",
    "data_std = data_stats[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_mean = np.transpose(data_mean.numpy(), axes=(0, 2, 3, 1))\n",
    "sep_std = np.transpose(data_std.numpy(), axes=(0, 2, 3, 1))\n",
    "\n",
    "tar_normalized = (tar - sep_mean)/ sep_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One random target vs predicted image (patch of shape [sz x sz])\n",
    "ncols = tar.shape[-1]\n",
    "_,ax = plt.subplots(figsize=(ncols*5, 2*5), nrows=2, ncols=ncols)\n",
    "img_idx = 10\n",
    "sz = 800\n",
    "hs = np.random.randint(tar.shape[1] - sz)\n",
    "ws = np.random.randint(tar.shape[2] - sz)\n",
    "for i in range(ncols):\n",
    "    ax[i,0].set_title(f'Target Channel {i+1}')\n",
    "    ax[i,0].imshow(tar[0, hs:hs+sz, ws:ws+sz, i])\n",
    "    ax[i,1].set_title(f'Predicted Channel {i+1}')\n",
    "    ax[i,1].imshow(pred[0, hs:hs+sz, ws:ws+sz, i])\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "# clean_ax(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = pred.shape[-1]\n",
    "img_sz = 3\n",
    "_,ax = plt.subplots(figsize=(4*img_sz,nrows*img_sz), ncols=4, nrows=nrows)\n",
    "idx = np.random.randint(len(pred))\n",
    "print(idx)\n",
    "for ch_id in range(nrows):\n",
    "    ax[ch_id,0].set_title(f'Target Channel {ch_id+1}')\n",
    "    ax[ch_id,0].imshow(tar_normalized[idx,..., ch_id], cmap='magma')\n",
    "    ax[ch_id,1].set_title(f'Predicted Channel {ch_id+1}')\n",
    "    ax[ch_id,1].imshow(pred[idx,:,:,ch_id], cmap='magma')\n",
    "    plot_error(\n",
    "        tar_normalized[idx,...,ch_id],\n",
    "        pred[idx,:,:,ch_id],\n",
    "        cmap = matplotlib.cm.coolwarm,\n",
    "        ax = ax[ch_id,2],\n",
    "        max_val = None\n",
    "    )\n",
    "\n",
    "    cropsz = 256\n",
    "    h_s = np.random.randint(0, tar_normalized.shape[1] - cropsz)\n",
    "    h_e = h_s + cropsz\n",
    "    w_s = np.random.randint(0, tar_normalized.shape[2] - cropsz)\n",
    "    w_e = w_s + cropsz\n",
    "\n",
    "    plot_error(\n",
    "        tar_normalized[idx,h_s:h_e,w_s:w_e, ch_id],\n",
    "        pred[idx,h_s:h_e,w_s:w_e,ch_id],\n",
    "        cmap = matplotlib.cm.coolwarm,\n",
    "        ax = ax[ch_id,3],\n",
    "        max_val = None\n",
    "    )\n",
    "\n",
    "    # Add rectangle to the region\n",
    "    rect = patches.Rectangle((w_s, h_s), w_e-w_s, h_e-h_s, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax[ch_id,2].add_patch(rect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "#### Compute metrics between predicted data and high-SNR (ground truth) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "Prepare data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_unnorm = []\n",
    "for i in range(pred.shape[-1]):\n",
    "    if sep_std.shape[-1] == 1:\n",
    "        temp_pred_unnorm = pred[...,i] * sep_std[...,0] + sep_mean[...,0]\n",
    "    else:\n",
    "        temp_pred_unnorm = pred[...,i] * sep_std[...,i] + sep_mean[...,i]\n",
    "    pred_unnorm.append(temp_pred_unnorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "Compute metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_range_inv_psnr(\n",
    "    pred: np.ndarray,\n",
    "    target: np.ndarray,\n",
    ") -> float:\n",
    "    \"\"\"Compute the average range-invariant PSNR.\"\"\"\n",
    "    psnr_arr = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        psnr_arr.append(scale_invariant_psnr(pred[i], target[i]))\n",
    "    return np.mean(psnr_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4dea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_normalized.min(), tar_normalized.max(), pred.min(), pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_arr = []\n",
    "psnr_arr = []\n",
    "rinv_psnr_arr = []\n",
    "ssim_arr = []\n",
    "for ch_id in range(pred.shape[-1]):\n",
    "    rmse =np.sqrt(((pred[...,ch_id] - tar_normalized[...,ch_id])**2).reshape(len(pred),-1).mean(axis=1))\n",
    "    rmse_arr.append(rmse)\n",
    "    # psnr = avg_psnr(tar_normalized[...,ch_id].copy(), pred[...,ch_id].copy())\n",
    "    rinv_psnr = avg_range_inv_psnr(tar_normalized[...,ch_id].copy(), pred[...,ch_id].copy())\n",
    "    # ssim_mean, ssim_std = avg_ssim(tar[...,ch_id], pred_unnorm[ch_id])\n",
    "    # psnr_arr.append(psnr)\n",
    "    rinv_psnr_arr.append(rinv_psnr)\n",
    "    # ssim_arr.append((ssim_mean,ssim_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{DataSplitType.name(eval_datasplit_type)}_P{eval_patch_size}_G{image_size_for_grid_centers}_M{mmse_count}_Sk{ignored_last_pixels}')\n",
    "# print('Rec Loss: ', np.round(rec_loss.mean(),3) )\n",
    "print('RMSE: ', ' <--> '.join([str(np.mean(x).round(3)) for x in rmse_arr]))\n",
    "print('PSNR: ', ' <--> '.join([str(x) for x in psnr_arr]))\n",
    "print('RangeInvPSNR: ',' <--> '.join([str(x) for x in rinv_psnr_arr]))\n",
    "print('SSIM: ',' <--> '.join([f'{round(x,3)}Â±{round(y,4)}' for (x,y) in ssim_arr]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab71a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2db9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usplit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "vscode": {
   "interpreter": {
    "hash": "e959a19f8af3b4149ff22eb57702a46c14a8caae5a2647a6be0b1f60abdfa4c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
